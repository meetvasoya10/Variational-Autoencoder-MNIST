# Variational Autoencoder (VAE) on MNIST

## Project Overview

This project implements a Variational Autoencoder (VAE) trained on the MNIST handwritten digits dataset.

VAEs are generative models that learn a structured, continuous latent space, enabling:

- Compression of input images into a low-dimensional representation
- Generation of new images by sampling from the latent space
- Smooth interpolation between latent representations

This repository provides:

- A clean implementation of a VAE in PyTorch
- Training on MNIST with reconstruction + KL loss
- Per-digit latent space sampling
- Visualizations using colormaps

---

## Architecture

The VAE consists of:

- **Encoder**: Maps 28x28 images to mean and log-variance vectors for a latent Gaussian
- **Reparameterization trick**: Samples latent vector from this Gaussian while keeping gradients flowing
- **Decoder**: Maps latent vector back to reconstructed image

---

## Objective Function

The training loss has two terms:

- **Reconstruction Loss**: Encourages the decoder to accurately reconstruct the input from the latent representation
- **KL Divergence**: Regularizes the latent space to resemble a standard normal distribution

This combination ensures the latent space is continuous and allows meaningful sampling and interpolation.

---

## Project Structure

```
models/vae.py                # VAE model class
utils/loss.py                # ELBO loss function
main.py                      # Model training script
per_digit_demo.py            # Visualization of digits 0–9
vae_mnist.pt                 # Saved model weights (after training)
requirements.txt             # Dependencies
README.md                    # Project description
.gitignore                   # File exclusions
```

---

## Visual Results

### Per-Digit Generation (0–9)

*Each digit generated by decoding a latent vector from test data corresponding to that digit.*



### Random Samples

*Decoded from random latent vectors drawn from standard normal distribution.*



---

## How to Run

### 1. Clone the repo

```bash
git clone https://github.com/your_username/vae-mnist.git
cd vae-mnist
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

### 3. Train the VAE

```bash
python main.py
```

### 4. Generate per-digit visualization

```bash
python per_digit_demo.py
```

---

## Key Concepts

- **Latent space**: The VAE learns a compressed, continuous representation of data
- **KL Divergence**: Helps the model learn a structured latent space aligned with a known distribution
- **Sampling**: New samples are generated by decoding vectors randomly drawn from the latent space
- **Reparameterization trick**: Allows gradient flow through stochastic nodes

---

## Future Extensions

- Conditional VAE (CVAE) to control generation by label
- Latent space interpolation demo
- Beta-VAE (KL weight tuning for disentanglement)
- Larger datasets (FashionMNIST, CelebA, etc.)

---
